{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "def load_inputs_from_file(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "# 从文件中读取数据\n",
    "loaded_inputs1 = load_inputs_from_file('inputs.pkl')\n",
    "loaded_inputs2 = load_inputs_from_file('true.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    1,     0,     0,  ...,  1009,  4423, 29973], device='cuda:0')\n",
      "tensor([    1,     0,     0,  ...,  1009,  4423, 29973], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(loaded_inputs1['input_ids'][0])\n",
    "print(loaded_inputs2['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cogvlm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/envs/cogvlm/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, LlamaTokenizer\n",
    "TOKENIZER_PATH = \"/mnt/pfs-mc0p4k/nlu/team/yuhaofu/modle_weight/vicuna-7b-v1.5\"\n",
    "tokenizer = LlamaTokenizer.from_pretrained(TOKENIZER_PATH)\n",
    "id = tokenizer.encode([' '])\n",
    "print(id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk> Can you point out 'green and cream double-decker bus'in the image and provide the bounding boxes of their location? \n",
      "<s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk> Can you point out 'green and cream double-decker bus' in the image and provide the bounding boxes of their location?\n"
     ]
    }
   ],
   "source": [
    "response1 = tokenizer.decode(loaded_inputs1['input_ids'][0])\n",
    "response2 = tokenizer.decode(loaded_inputs2['input_ids'][0])\n",
    "print(response1)\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s>\u0006\u0005\u0004<s>\n"
     ]
    }
   ],
   "source": [
    "response = tokenizer.decode('29871')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def parse_bbox_from_response(response):\n",
    "    \"\"\"\n",
    "    从模型响应中解析边界框坐标\n",
    "    \"\"\"\n",
    "    # 寻找[x, y, x2, y2]格式的坐标，包括整数和小数\n",
    "    pattern = r'\\[\\[(\\d+),\\s*(\\d+),\\s*(\\d+),\\s*(\\d+)\\]\\]'\n",
    "    match = re.search(pattern, response)\n",
    "    \n",
    "    if match:\n",
    "        try:\n",
    "            x1 = int(match.group(1))  # 提取整数值\n",
    "            y1 = int(match.group(2))\n",
    "            x2 = int(match.group(3))\n",
    "            y2 = int(match.group(4))\n",
    "            # 验证坐标有效性，如果仍需要确保有效性范围\n",
    "            if x1 <= x2 and y1 <= y2:\n",
    "                x1 = x1/1000\n",
    "                x2 = x2/1000\n",
    "                y1 = y1/1000\n",
    "                y2 = y2/1000\n",
    "                return [x1, y1, x2, y2]\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    # 不符合条件的返回None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27, 0.159, 0.624, 0.975]\n"
     ]
    }
   ],
   "source": [
    "response = \"[[270,159,624,975]]\"\n",
    "bbox = parse_bbox_from_response(response)\n",
    "print(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "不满足条件的样本ID： []\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "file1 = '/mnt/pfs-mc0p4k/nlu/team/yuhaofu/data/LLaVA-CoT-100k/fgeo_1_10_bbox.json'\n",
    "file2 = '/mnt/pfs-mc0p4k/nlu/team/yuhaofu/data/LLaVA-CoT-100k/filter_geoqa+_1_10.json'\n",
    "# 读取两个 JSON 文件\n",
    "with open(file1, 'r') as f:\n",
    "    data1 = json.load(f)\n",
    "\n",
    "with open(file2, 'r') as f:\n",
    "    data2 = json.load(f)\n",
    "\n",
    "# 存储不满足条件的样本 ID\n",
    "mismatched_ids = []\n",
    "\n",
    "# 遍历第一个 JSON 文件中的每个记录\n",
    "for item1 in data1:\n",
    "    id1 = item1['id']\n",
    "    \n",
    "    # 在第二个 JSON 文件中找到匹配的记录\n",
    "    item2 = next((item for item in data2 if item[\"id\"] == id1), None)\n",
    "    if item2 is None:\n",
    "        continue\n",
    "\n",
    "    # 检查第二个文件的 conversations 长度是否为第一个文件的两倍\n",
    "    if len(item2['conversations']) != 2 * len(item1['conversations']):\n",
    "        mismatched_ids.append(id1)\n",
    "\n",
    "# 打印不满足条件的样本 ID\n",
    "print(\"不满足条件的样本ID：\", mismatched_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 过滤掉整张图片的描述\n",
    "import json\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"Calculate the Intersection over Union (IoU) of two bounding boxes.\"\"\"\n",
    "    x_left = max(box1[0], box2[0])\n",
    "    y_top = max(box1[1], box2[1])\n",
    "    x_right = min(box1[2], box2[2])\n",
    "    y_bottom = min(box1[3], box2[3])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "\n",
    "    iou = intersection_area / float(box1_area + box2_area - intersection_area)\n",
    "    return iou\n",
    "\n",
    "file_path = '/mnt/pfs-mc0p4k/nlu/team/yuhaofu/data/LLaVA-CoT-100k/fgeo_1_10_bbox.json'\n",
    "with open(file_path, 'r') as f:\n",
    "    data1 = json.load(f)\n",
    "\n",
    "reference_box = [0, 0, 1, 1]  # The reference box to compare against\n",
    "for sample_data in data1:\n",
    "    for conversation in sample_data[\"conversations\"]:\n",
    "        for attr in [\"<CAPTION>\", \"<REASONING>\"]:\n",
    "            if conversation[attr] is not None:\n",
    "                for item in conversation[attr]:\n",
    "                    iou = calculate_iou(item[\"bbox\"], reference_box)\n",
    "                    if iou > 0.8:\n",
    "                        item[\"bbox\"] = None\n",
    "\n",
    "# Output the modified sample_data\n",
    "with open('/mnt/pfs-mc0p4k/nlu/team/yuhaofu/data/LLaVA-CoT-100k/test.json', 'w') as f:\n",
    "    json.dump(data1, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of bounding boxes that are not None: 48\n"
     ]
    }
   ],
   "source": [
    "# 统计有效bbox个数\n",
    "file_path = '/mnt/pfs-mc0p4k/nlu/team/yuhaofu/data/LLaVA-CoT-100k/test.json'\n",
    "with open(file_path, 'r') as f:\n",
    "    data1 = json.load(f)\n",
    "\n",
    "count = 0\n",
    "for sample_data in data1:\n",
    "    for conversation in sample_data[\"conversations\"]:\n",
    "        for attr in [\"<CAPTION>\", \"<REASONING>\"]:\n",
    "            if conversation[attr] is not None:\n",
    "                for item in conversation[attr]:\n",
    "                    if item['bbox'] is not None:\n",
    "                        count += 1\n",
    "print(f\"The number of bounding boxes that are not None: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将bbox放回原文本\n",
    "import json\n",
    "import re\n",
    "\n",
    "# 读取两个 JSON 文件\n",
    "with open(file1, 'r') as f:\n",
    "    data1 = json.load(f)\n",
    "\n",
    "with open(file2, 'r') as f:\n",
    "    data2 = json.load(f)\n",
    "\n",
    "# 遍历第一个 JSON 文件中的每个记录\n",
    "for item1 in data1:\n",
    "    id1 = item1['id']\n",
    "    \n",
    "    # 在第二个 JSON 文件中找到匹配的记录\n",
    "    item2 = next((item for item in data2 if item[\"id\"] == id1), None)\n",
    "    if item2 is None:\n",
    "        continue\n",
    "\n",
    "    # 遍历第一个记录中的 conversations，同时与第二个文件的对话对应\n",
    "    for idx, conversation1 in enumerate(item1['conversations']):\n",
    "        if idx * 2 + 1 >= len(item2['conversations']):\n",
    "            break\n",
    "        \n",
    "        # 获取对应的 from gpt 文本\n",
    "        gpt_response = item2['conversations'][idx * 2 + 1]['value']\n",
    "        \n",
    "        # 处理 <CAPTION>\n",
    "        if \"<CAPTION>\" in conversation1 and conversation1[\"<CAPTION>\"] is not None:\n",
    "            caption_phrases = {phrase[\"content\"]: phrase[\"bbox\"] for phrase in conversation1[\"<CAPTION>\"] if phrase[\"bbox\"] is not None}\n",
    "            caption_content = re.search(r'<CAPTION>(.*?)</CAPTION>', gpt_response, re.DOTALL)\n",
    "            if caption_content:\n",
    "                updated_caption = caption_content.group(1)\n",
    "                for phrase, bbox in caption_phrases.items():\n",
    "                    if phrase in updated_caption:\n",
    "                        updated_caption = updated_caption.replace(phrase, f\"{phrase} {bbox}\")\n",
    "                gpt_response = gpt_response.replace(caption_content.group(1), updated_caption)\n",
    "        \n",
    "        # 处理 <REASONING>\n",
    "        if \"<REASONING>\" in conversation1 and conversation1[\"<REASONING>\"] is not None:\n",
    "            reasoning_phrases = {phrase[\"content\"]: phrase[\"bbox\"] for phrase in conversation1[\"<REASONING>\"] if phrase[\"bbox\"] is not None}\n",
    "            reasoning_content = re.search(r'<REASONING>(.*?)</REASONING>', gpt_response, re.DOTALL)\n",
    "            if reasoning_content:\n",
    "                updated_reasoning = reasoning_content.group(1)\n",
    "                for phrase, bbox in reasoning_phrases.items():\n",
    "                    if phrase in updated_reasoning:\n",
    "                        updated_reasoning = updated_reasoning.replace(phrase, f\"{phrase} {bbox}\")\n",
    "                gpt_response = gpt_response.replace(reasoning_content.group(1), updated_reasoning)\n",
    "\n",
    "        # 更新 gpt_response\n",
    "        item2['conversations'][idx * 2 + 1]['value'] = gpt_response\n",
    "\n",
    "# 输出处理后的 JSON 数据\n",
    "with open('/mnt/pfs-mc0p4k/nlu/team/yuhaofu/data/LLaVA-CoT-100k/test.json', 'w') as f:\n",
    "    json.dump(data2, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cogvlm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/envs/cogvlm/lib/python3.11/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import argparse\n",
    "from PIL import Image\n",
    "import datetime\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data import Dataset, DataLoader, DistributedSampler\n",
    "from transformers import AutoModelForCausalLM, LlamaTokenizer\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "TOKENIZER_PATH = \"/lpai/volumes/ss-nlu-ali-sh/lizr/yuhaofu/model/vicuna-7b-v1.5\"\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    自定义的collate函数，用于处理PIL.Image对象\n",
    "    \"\"\"\n",
    "    id_list = [item['id'] for item in batch]\n",
    "    image_list = [item['image'] for item in batch]\n",
    "    conversations_list = [item['conversations'] for item in batch]\n",
    "    original_image_path_list = [item['original_image_path'] for item in batch]\n",
    "    \n",
    "    return {\n",
    "        'id': id_list,\n",
    "        'image': image_list,\n",
    "        'conversations': conversations_list,\n",
    "        'original_image_path': original_image_path_list\n",
    "\n",
    "    }\n",
    "class BboxDataset(Dataset):\n",
    "    \"\"\"\n",
    "    用于加载预处理好的图像和标注数据的数据集\n",
    "    \"\"\"\n",
    "    def __init__(self, json_file, image_base_dir):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            json_file (str): 包含图像路径和标注的JSON文件路径\n",
    "            image_base_dir (str): 图像文件的基础目录\n",
    "        \"\"\"\n",
    "        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "            self.data = json.load(f)\n",
    "        self.image_base_dir = image_base_dir\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        image_path = os.path.join(self.image_base_dir, item['image'])\n",
    "        \n",
    "        # 加载图像\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {e}\")\n",
    "            # 返回一个占位图像\n",
    "            image = Image.new('RGB', (224, 224), color='gray')\n",
    "        \n",
    "        conversations = item['conversations']\n",
    "        # 深度复制会话数据，防止在处理过程中修改原始数据\n",
    "        # conversations = []\n",
    "        # for conv in item['conversations']:\n",
    "        #     conversation = {}\n",
    "        #     for key, value in conv.items():\n",
    "        #         conversation[key] = value.copy() if isinstance(value, list) else value\n",
    "        #     conversations.append(conversation)\n",
    "            \n",
    "        return {\n",
    "            'id': item['id'],\n",
    "            'image': image,\n",
    "            'conversations': conversations,\n",
    "            'original_image_path': item['image']\n",
    "        }\n",
    "\n",
    "\n",
    "def parse_bbox_from_response(response):\n",
    "    \"\"\"\n",
    "    从模型响应中解析边界框坐标\n",
    "    \"\"\"\n",
    "    # 寻找[x, y, x2, y2]格式的坐标，包括整数和小数\n",
    "    pattern = r'\\[\\[(\\d+),\\s*(\\d+),\\s*(\\d+),\\s*(\\d+)\\]\\]'\n",
    "    match = re.search(pattern, response)\n",
    "    \n",
    "    if match:\n",
    "        try:\n",
    "            x1 = int(match.group(1))  # 提取整数值\n",
    "            y1 = int(match.group(2))\n",
    "            x2 = int(match.group(3))\n",
    "            y2 = int(match.group(4))\n",
    "            # 验证坐标有效性，如果仍需要确保有效性范围\n",
    "            if x1 <= x2 and y1 <= y2:\n",
    "                x1 = x1/1000\n",
    "                x2 = x2/1000\n",
    "                y1 = y1/1000\n",
    "                y2 = y2/1000\n",
    "                return [x1, y1, x2, y2]\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    # 不符合条件的返回None\n",
    "    return None\n",
    "def bbox_convert(bbox):\n",
    "    # 将每个元素乘以1000\n",
    "    scaled_bbox = [coord * 1000 for coord in bbox]\n",
    "    return f\"[{scaled_bbox}]\"\n",
    "\n",
    "\n",
    "def generate_bbox_prompt(bbox, content):\n",
    "    \"\"\"\n",
    "    为列表元素生成提示，用于请求模型生成边界框\n",
    "    \"\"\"\n",
    "    return (f\"Tell me if the designated area {bbox} in the picture is '{content}', yes or no?\")\n",
    "\n",
    "\n",
    "def setup_distributed(rank, world_size):\n",
    "    \"\"\"\n",
    "    设置分布式训练环境\n",
    "    \"\"\"\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "    \n",
    "    # 初始化进程组\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size, timeout=datetime.timedelta(seconds=3600))\n",
    "    \n",
    "    # 设置GPU设备\n",
    "    torch.cuda.set_device(rank)\n",
    "\n",
    "\n",
    "def cleanup_distributed():\n",
    "    \"\"\"\n",
    "    清理分布式训练环境\n",
    "    \"\"\"\n",
    "    dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_json = \"/mnt/pfs-mc0p4k/nlu/team/yuhaofu/data/LLaVA-CoT-100k/json/filter_entire_image_caption.json\"\n",
    "image_dir = \"/mnt/pfs-mc0p4k/nlu/team/yuhaofu/data/LLaVA-CoT-100k\"\n",
    "dataset = BboxDataset(data_json, image_dir)\n",
    "# sampler = DistributedSampler(\n",
    "#     dataset, \n",
    "#     num_replicas=world_size, \n",
    "#     rank=rank, \n",
    "#     shuffle=False\n",
    "# )\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset, \n",
    "    batch_size=1,  # 设置为1，每次处理一个样本\n",
    "    # sampler=sampler,\n",
    "    num_workers=1,\n",
    "    collate_fn=custom_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image /lpai/volumes/ss-nlu-ali-sh/lizr/yuhaofu/data/LLaVa-CoT-100k/coco/train2017/000000338745.jpg: [Errno 2] No such file or directory: '/lpai/volumes/ss-nlu-ali-sh/lizr/yuhaofu/data/LLaVa-CoT-100k/coco/train2017/000000338745.jpg'\n",
      "Error loading image /lpai/volumes/ss-nlu-ali-sh/lizr/yuhaofu/data/LLaVa-CoT-100k/pisc/image/09543.jpg: [Errno 2] No such file or directory: '/lpai/volumes/ss-nlu-ali-sh/lizr/yuhaofu/data/LLaVa-CoT-100k/pisc/image/09543.jpg'\n",
      "Error loading image /lpai/volumes/ss-nlu-ali-sh/lizr/yuhaofu/data/LLaVa-CoT-100k/coco/train2017/000000440900.jpg: [Errno 2] No such file or directory: '/lpai/volumes/ss-nlu-ali-sh/lizr/yuhaofu/data/LLaVa-CoT-100k/coco/train2017/000000440900.jpg'\n",
      "[0.27, 0.159, 0.624, 0.975]\n",
      "[0.0, 0.711, 0.35, 0.993]\n",
      "[0.27, 0.159, 0.624, 0.975]\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    sample_id = batch['id'][0]\n",
    "    image = batch['image'][0]\n",
    "    conversations = batch['conversations'][0]  # 一批中的第一个样本\n",
    "    image_path = batch['original_image_path'][0]\n",
    "\n",
    "    # image_path = os.path.join(args.image_dir, image_path)\n",
    "    # image = Image.open(image_path).convert('RGB')\n",
    "    processed_conversations = []\n",
    "    for conversation in conversations:\n",
    "        processed_conv = {}\n",
    "        # print(conversation)\n",
    "        # 处理 <CAPTION> 列表\n",
    "        # def process_elements(elements, model, tokenizer, image, rank, args):\n",
    "        #     results_with_bbox = []\n",
    "\n",
    "        #     for element in elements:\n",
    "        #         if element['bbox'] is not None:\n",
    "        #             bbox = element['bbox']\n",
    "        #             content = element['content']\n",
    "\n",
    "        #             convert_bbox = bbox_convert(bbox)\n",
    "        #             prompt = generate_bbox_prompt(convert_bbox, content)\n",
    "\n",
    "        #             input_by_model = model.module.build_conversation_input_ids(\n",
    "        #                 tokenizer, \n",
    "        #                 query=prompt,\n",
    "        #                 history=None, \n",
    "        #                 images=[image]\n",
    "        #             )\n",
    "                    \n",
    "        #             inputs = {\n",
    "        #                 'input_ids': input_by_model['input_ids'].unsqueeze(0).to(rank),\n",
    "        #                 'token_type_ids': input_by_model['token_type_ids'].unsqueeze(0).to(rank),\n",
    "        #                 'attention_mask': input_by_model['attention_mask'].unsqueeze(0).to(rank),\n",
    "        #                 'images': [[input_by_model['images'][0].to(rank).to(torch.bfloat16)]] if image is not None else None,\n",
    "        #             }\n",
    "                    \n",
    "        #             if 'cross_images' in input_by_model and input_by_model['cross_images']:\n",
    "        #                 inputs['cross_images'] = [[input_by_model['cross_images'][0].to(rank).to(torch.bfloat16)]]\n",
    "                    \n",
    "        #             # 生成参数\n",
    "        #             gen_kwargs = {\n",
    "        #                 \"max_length\": args.max_tokens,\n",
    "        #                 \"do_sample\": False\n",
    "        #             }\n",
    "                    \n",
    "        #             # 生成响应\n",
    "        #             outputs = model.module.generate(**inputs, **gen_kwargs)\n",
    "        #             outputs = outputs[:, inputs['input_ids'].shape[1]:]\n",
    "        #             response = tokenizer.decode(outputs[0])\n",
    "        #             # print('image_path:', image_path, 'prompt:', prompt)\n",
    "        #             # print('response:', response)\n",
    "        #             response = response.split(\"</s>\")[0]\n",
    "        #             print(response)\n",
    "        #             flag = 1\n",
    "        #             if 'yes' in response.lower():\n",
    "        #                 bbox = bbox\n",
    "        #             elif 'no' in response.lower():\n",
    "        #                 bbox = element['bbox']\n",
    "        #             else:\n",
    "        #                 flag = 0\n",
    "        #         else:\n",
    "        #             bbox = element['bbox']\n",
    "        #             flag = 1\n",
    "        #         results_with_bbox.append({\n",
    "        #             \"content\": element['content'],\n",
    "        #             \"bbox\": bbox,\n",
    "        #             \"flag\": flag\n",
    "        #         })\n",
    "        #         print(flag)\n",
    "            \n",
    "        #     return results_with_bbox\n",
    "        if \"<CAPTION>\" in conversation and conversation[\"<CAPTION>\"]:\n",
    "            caption_elements = conversation[\"<CAPTION>\"]\n",
    "            for element in caption_elements:\n",
    "                if element['bbox'] is not None:\n",
    "                    bbox = element['bbox']\n",
    "                    content = element['content']\n",
    "                    print(bbox)\n",
    "                    convert_bbox = bbox_convert(bbox)\n",
    "                    prompt = generate_bbox_prompt(convert_bbox, content)\n",
    "                    # print(convert_bbox)\n",
    "                    # print(prompt)\n",
    "            # processed_conv[\"<CAPTION>\"] = process_elements(\n",
    "            #     caption_elements, model, tokenizer, image, rank, args\n",
    "            # )\n",
    "        else:\n",
    "            processed_conv[\"<CAPTION>\"] = None\n",
    "        break\n",
    "    \n",
    "\n",
    "        processed_conversations.append(processed_conv)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogvlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
